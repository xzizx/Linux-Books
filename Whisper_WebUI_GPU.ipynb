{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xzizx/Linux-Books/blob/master/Whisper_WebUI_GPU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking out WebUI from Git"
      ],
      "metadata": {
        "id": "7Y78bxUrVzPF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h85P7mbOVfby",
        "outputId": "fbb49ede-4fc8-43c4-e2c0-3665085bbc00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'whisper-webui'...\n",
            "remote: Enumerating objects: 412, done.\u001b[K\n",
            "remote: Counting objects: 100% (412/412), done.\u001b[K\n",
            "remote: Compressing objects: 100% (404/404), done.\u001b[K\n",
            "remote: Total 412 (delta 267), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (412/412), 83.40 KiB | 499.00 KiB/s, done.\n",
            "Resolving deltas: 100% (267/267), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://huggingface.co/spaces/aadnk/whisper-webui"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optional: Update Git repository"
      ],
      "metadata": {
        "id": "-mZsftNvqYze"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cd whisper-webui/ && git pull origin"
      ],
      "metadata": {
        "id": "rJYJGFJPqbdL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installing dependencies"
      ],
      "metadata": {
        "id": "ohLec8LfWBeM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cd whisper-webui/ && pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-jCbFjWpV_ci",
        "outputId": "b057fcd5-5e0d-441d-e0ea-78c5a57c8e83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/openai/whisper.git (from -r requirements.txt (line 1))\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-nm9s719t\n",
            "  Running command git clone -q https://github.com/openai/whisper.git /tmp/pip-req-build-nm9s719t\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 6.5 MB/s \n",
            "\u001b[?25hCollecting ffmpeg-python==0.2.0\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Collecting gradio==3.13.0\n",
            "  Downloading gradio-3.13.0-py3-none-any.whl (13.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 13.8 MB 29.6 MB/s \n",
            "\u001b[?25hCollecting yt-dlp\n",
            "  Downloading yt_dlp-2022.11.11-py2.py3-none-any.whl (2.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.8 MB 65.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torchaudio in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 6)) (0.13.0+cu116)\n",
            "Requirement already satisfied: altair in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 7)) (4.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from whisper==1.0->-r requirements.txt (line 1)) (1.21.6)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from whisper==1.0->-r requirements.txt (line 1)) (1.13.0+cu116)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from whisper==1.0->-r requirements.txt (line 1)) (4.64.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.8/dist-packages (from whisper==1.0->-r requirements.txt (line 1)) (9.0.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.8/dist-packages (from ffmpeg-python==0.2.0->-r requirements.txt (line 3)) (0.16.0)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.8/dist-packages (from gradio==3.13.0->-r requirements.txt (line 4)) (1.10.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from gradio==3.13.0->-r requirements.txt (line 4)) (1.3.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from gradio==3.13.0->-r requirements.txt (line 4)) (3.2.2)\n",
            "Collecting orjson\n",
            "  Downloading orjson-3.8.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (278 kB)\n",
            "\u001b[K     |████████████████████████████████| 278 kB 68.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from gradio==3.13.0->-r requirements.txt (line 4)) (2.23.0)\n",
            "Collecting uvicorn\n",
            "  Downloading uvicorn-0.20.0-py3-none-any.whl (56 kB)\n",
            "\u001b[K     |████████████████████████████████| 56 kB 6.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.8/dist-packages (from gradio==3.13.0->-r requirements.txt (line 4)) (7.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.8/dist-packages (from gradio==3.13.0->-r requirements.txt (line 4)) (2022.11.0)\n",
            "Collecting markdown-it-py[linkify,plugins]\n",
            "  Downloading markdown_it_py-2.1.0-py3-none-any.whl (84 kB)\n",
            "\u001b[K     |████████████████████████████████| 84 kB 4.5 MB/s \n",
            "\u001b[?25hCollecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting pycryptodome\n",
            "  Downloading pycryptodome-3.16.0-cp35-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 66.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from gradio==3.13.0->-r requirements.txt (line 4)) (6.0)\n",
            "Collecting websockets>=10.0\n",
            "  Downloading websockets-10.4-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (106 kB)\n",
            "\u001b[K     |████████████████████████████████| 106 kB 76.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from gradio==3.13.0->-r requirements.txt (line 4)) (2.11.3)\n",
            "Collecting fastapi\n",
            "  Downloading fastapi-0.88.0-py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 5.1 MB/s \n",
            "\u001b[?25hCollecting python-multipart\n",
            "  Downloading python-multipart-0.0.5.tar.gz (32 kB)\n",
            "Collecting ffmpy\n",
            "  Downloading ffmpy-0.3.0.tar.gz (4.8 kB)\n",
            "Collecting h11<0.13,>=0.11\n",
            "  Downloading h11-0.12.0-py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 4.2 MB/s \n",
            "\u001b[?25hCollecting paramiko\n",
            "  Downloading paramiko-2.12.0-py2.py3-none-any.whl (213 kB)\n",
            "\u001b[K     |████████████████████████████████| 213 kB 66.8 MB/s \n",
            "\u001b[?25hCollecting httpx\n",
            "  Downloading httpx-0.23.1-py3-none-any.whl (84 kB)\n",
            "\u001b[K     |████████████████████████████████| 84 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from gradio==3.13.0->-r requirements.txt (line 4)) (3.8.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers->-r requirements.txt (line 2)) (21.3)\n",
            "Collecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 71.0 MB/s \n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 48.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers->-r requirements.txt (line 2)) (3.8.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers->-r requirements.txt (line 2)) (2022.6.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers->-r requirements.txt (line 2)) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers->-r requirements.txt (line 2)) (3.0.9)\n",
            "Collecting pycryptodomex\n",
            "  Downloading pycryptodomex-3.16.0-cp35-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 31.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.8/dist-packages (from yt-dlp->-r requirements.txt (line 5)) (2022.9.24)\n",
            "Collecting brotli\n",
            "  Downloading Brotli-1.0.9-cp38-cp38-manylinux1_x86_64.whl (357 kB)\n",
            "\u001b[K     |████████████████████████████████| 357 kB 38.4 MB/s \n",
            "\u001b[?25hCollecting mutagen\n",
            "  Downloading mutagen-1.46.0-py3-none-any.whl (193 kB)\n",
            "\u001b[K     |████████████████████████████████| 193 kB 74.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.8/dist-packages (from altair->-r requirements.txt (line 7)) (4.3.3)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.8/dist-packages (from altair->-r requirements.txt (line 7)) (0.4)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.8/dist-packages (from altair->-r requirements.txt (line 7)) (0.12.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=3.0->altair->-r requirements.txt (line 7)) (22.1.0)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=3.0->altair->-r requirements.txt (line 7)) (5.10.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=3.0->altair->-r requirements.txt (line 7)) (0.19.2)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from importlib-resources>=1.4.0->jsonschema>=3.0->altair->-r requirements.txt (line 7)) (3.11.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->gradio==3.13.0->-r requirements.txt (line 4)) (2022.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->gradio==3.13.0->-r requirements.txt (line 4)) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->gradio==3.13.0->-r requirements.txt (line 4)) (1.15.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->gradio==3.13.0->-r requirements.txt (line 4)) (1.8.2)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->gradio==3.13.0->-r requirements.txt (line 4)) (2.1.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->gradio==3.13.0->-r requirements.txt (line 4)) (6.0.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->gradio==3.13.0->-r requirements.txt (line 4)) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->gradio==3.13.0->-r requirements.txt (line 4)) (4.0.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->gradio==3.13.0->-r requirements.txt (line 4)) (1.3.3)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.8/dist-packages (from yarl<2.0,>=1.0->aiohttp->gradio==3.13.0->-r requirements.txt (line 4)) (2.10)\n",
            "Collecting starlette==0.22.0\n",
            "  Downloading starlette-0.22.0-py3-none-any.whl (64 kB)\n",
            "\u001b[K     |████████████████████████████████| 64 kB 4.1 MB/s \n",
            "\u001b[?25hCollecting anyio<5,>=3.4.0\n",
            "  Downloading anyio-3.6.2-py3-none-any.whl (80 kB)\n",
            "\u001b[K     |████████████████████████████████| 80 kB 11.4 MB/s \n",
            "\u001b[?25hCollecting sniffio>=1.1\n",
            "  Downloading sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
            "Collecting rfc3986[idna2008]<2,>=1.3\n",
            "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
            "Collecting httpcore<0.17.0,>=0.15.0\n",
            "  Downloading httpcore-0.16.2-py3-none-any.whl (68 kB)\n",
            "\u001b[K     |████████████████████████████████| 68 kB 9.9 MB/s \n",
            "\u001b[?25h  Downloading httpcore-0.16.1-py3-none-any.whl (68 kB)\n",
            "\u001b[K     |████████████████████████████████| 68 kB 9.1 MB/s \n",
            "\u001b[?25h  Downloading httpcore-0.16.0-py3-none-any.whl (68 kB)\n",
            "\u001b[K     |████████████████████████████████| 68 kB 10.3 MB/s \n",
            "\u001b[?25h  Downloading httpcore-0.15.0-py3-none-any.whl (68 kB)\n",
            "\u001b[K     |████████████████████████████████| 68 kB 377 kB/s \n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->gradio==3.13.0->-r requirements.txt (line 4)) (2.0.1)\n",
            "Collecting mdurl~=0.1\n",
            "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Collecting mdit-py-plugins\n",
            "  Downloading mdit_py_plugins-0.3.3-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 8.7 MB/s \n",
            "\u001b[?25hCollecting linkify-it-py~=1.0\n",
            "  Downloading linkify_it_py-1.0.3-py3-none-any.whl (19 kB)\n",
            "Collecting uc-micro-py\n",
            "  Downloading uc_micro_py-1.0.1-py3-none-any.whl (6.2 kB)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->gradio==3.13.0->-r requirements.txt (line 4)) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->gradio==3.13.0->-r requirements.txt (line 4)) (0.11.0)\n",
            "Collecting bcrypt>=3.1.3\n",
            "  Downloading bcrypt-4.0.1-cp36-abi3-manylinux_2_24_x86_64.whl (593 kB)\n",
            "\u001b[K     |████████████████████████████████| 593 kB 67.2 MB/s \n",
            "\u001b[?25hCollecting pynacl>=1.0.1\n",
            "  Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (856 kB)\n",
            "\u001b[K     |████████████████████████████████| 856 kB 73.1 MB/s \n",
            "\u001b[?25hCollecting cryptography>=2.5\n",
            "  Downloading cryptography-38.0.4-cp36-abi3-manylinux_2_24_x86_64.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 70.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.8/dist-packages (from cryptography>=2.5->paramiko->gradio==3.13.0->-r requirements.txt (line 4)) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi>=1.12->cryptography>=2.5->paramiko->gradio==3.13.0->-r requirements.txt (line 4)) (2.21)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->gradio==3.13.0->-r requirements.txt (line 4)) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->gradio==3.13.0->-r requirements.txt (line 4)) (3.0.4)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.8/dist-packages (from uvicorn->gradio==3.13.0->-r requirements.txt (line 4)) (7.1.2)\n",
            "Building wheels for collected packages: whisper, ffmpy, python-multipart\n",
            "  Building wheel for whisper (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for whisper: filename=whisper-1.0-py3-none-any.whl size=1175324 sha256=8c2c1cf09166f2e1992a5456a8314d4c3295dbc1d00a4dc7687ac84e8c89b559\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-90udbv7p/wheels/a7/70/18/b7693c07b1d18b3dafb328f5d0496aa0d41a9c09ef332fd8e6\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.0-py3-none-any.whl size=4711 sha256=f6ea42052f73892aabf14733a61e1053243964f3b5e2a351f2183ee38da65399\n",
            "  Stored in directory: /root/.cache/pip/wheels/ff/5b/59/913b443e7369dc04b61f607a746b6f7d83fb65e2e19fcc958d\n",
            "  Building wheel for python-multipart (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-multipart: filename=python_multipart-0.0.5-py3-none-any.whl size=31678 sha256=f248605ab84f921a4b5020b67160e05426e1bd7d08a75a9f5a105b734aafddaf\n",
            "  Stored in directory: /root/.cache/pip/wheels/9e/fc/1c/cf980e6413d3ee8e70cd8f39e2366b0f487e3e221aeb452eb0\n",
            "Successfully built whisper ffmpy python-multipart\n",
            "Installing collected packages: sniffio, mdurl, uc-micro-py, rfc3986, markdown-it-py, h11, anyio, tokenizers, starlette, pynacl, mdit-py-plugins, linkify-it-py, huggingface-hub, httpcore, cryptography, bcrypt, websockets, uvicorn, transformers, python-multipart, pydub, pycryptodomex, pycryptodome, paramiko, orjson, mutagen, httpx, ffmpy, ffmpeg-python, fastapi, brotli, yt-dlp, whisper, gradio\n",
            "Successfully installed anyio-3.6.2 bcrypt-4.0.1 brotli-1.0.9 cryptography-38.0.4 fastapi-0.88.0 ffmpeg-python-0.2.0 ffmpy-0.3.0 gradio-3.13.0 h11-0.12.0 httpcore-0.15.0 httpx-0.23.1 huggingface-hub-0.11.1 linkify-it-py-1.0.3 markdown-it-py-2.1.0 mdit-py-plugins-0.3.3 mdurl-0.1.2 mutagen-1.46.0 orjson-3.8.3 paramiko-2.12.0 pycryptodome-3.16.0 pycryptodomex-3.16.0 pydub-0.25.1 pynacl-1.5.0 python-multipart-0.0.5 rfc3986-1.5.0 sniffio-1.3.0 starlette-0.22.0 tokenizers-0.13.2 transformers-4.25.1 uc-micro-py-1.0.1 uvicorn-0.20.0 websockets-10.4 whisper-1.0 yt-dlp-2022.11.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run WebUI"
      ],
      "metadata": {
        "id": "x55yRVjOWW3c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cd whisper-webui/ && python app.py --input_audio_max_duration -1 --share True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IuL5nGTIWYTY",
        "outputId": "c6affaca-463b-40d6-a720-8e1ea0379545"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on local URL:  http://127.0.0.1:7860\n",
            "Running on public URL: https://a37f9a1216e4aa1a.gradio.app\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades (NEW!), check out Spaces: https://huggingface.co/spaces\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/gradio/blocks.py\", line 1606, in block_thread\n",
            "    time.sleep(0.1)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"app.py\", line 397, in <module>\n",
            "    create_ui(**args)\n",
            "  File \"app.py\", line 377, in create_ui\n",
            "    demo.launch(share=share, server_name=server_name, server_port=server_port)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/gradio/blocks.py\", line 1528, in launch\n",
            "    self.block_thread()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/gradio/blocks.py\", line 1609, in block_thread\n",
            "    self.server.close()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/gradio/networking.py\", line 44, in close\n",
            "    self.thread.join()\n",
            "  File \"/usr/lib/python3.8/threading.py\", line 1011, in join\n",
            "    self._wait_for_tstate_lock()\n",
            "  File \"/usr/lib/python3.8/threading.py\", line 1027, in _wait_for_tstate_lock\n",
            "    elif lock.acquire(block, timeout):\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "07ESBkbHdj-N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Google Drive\n",
        "\n",
        "This version of the WebUI can automatically save the generated SRT/VTT/Transcript files to Google Drive (requires Google Drive authorization)."
      ],
      "metadata": {
        "id": "Qr-wItBTdr0d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mount Google Drive"
      ],
      "metadata": {
        "id": "iEu9Q5yreDEw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KHNLATd9d_CP",
        "outputId": "c0d2c295-f673-4523-c26e-6774dc2a757b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let Whisper use Google Drive as Temp Directory. Note that the directory \"Whisper\" must exist on your Google Drive (or rename it)."
      ],
      "metadata": {
        "id": "fhbQGntFeEwJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cd whisper-webui/ && python app.py --input_audio_max_duration -1 --share True --auto_parallel True --output_dir /content/drive/MyDrive/Whisper"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qaXqjHuCecAg",
        "outputId": "e2beb402-fa51-4c30-dd23-47ff2ea1b552"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Auto parallel] Using GPU devices ['0'] and 2 CPU cores for VAD/transcription.\n",
            "Running on local URL:  http://127.0.0.1:7860\n",
            "Running on public URL: https://c87462a791b4fa99.gradio.app\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades (NEW!), check out Spaces: https://huggingface.co/spaces\n",
            "/usr/local/lib/python3.8/dist-packages/torch/hub.py:267: UserWarning: You are about to download and run code from an untrusted repository. In a future release, this won't be allowed. To add the repository to your trusted list, change the command to {calling_fn}(..., trust_repo=False) and a command prompt will appear asking for an explicit confirmation of trust, or load(..., trust_repo=True), which will assume that the prompt is to be answered with 'yes'. You can also use load(..., trust_repo='check') which will only prompt for confirmation if the repo is not already trusted. This will eventually be the default behaviour\n",
            "  warnings.warn(\n",
            "Downloading: \"https://github.com/snakers4/silero-vad/zipball/master\" to /root/.cache/torch/hub/master.zip\n",
            "Created Silerio model\n",
            "Parallel VAD: Executing chunk from 0 to 120 on CPU device 0\n",
            "Parallel VAD: Executing chunk from 120 to 206.921 on CPU device 1\n",
            "Using cache found in /root/.cache/torch/hub/snakers4_silero-vad_master\n",
            "Using cache found in /root/.cache/torch/hub/snakers4_silero-vad_master\n",
            "Loaded Silerio model from cache.\n",
            "Getting timestamps from audio file: /tmp/Video Podcast 2 SpotifyAnchor 有料エピソードを始めます rQycK6cBS8or7ft0dto.webm, start: 0, duration: 120\n",
            "Processing VAD in chunk from 00:00.000 to 02:00.000\n",
            "Loaded Silerio model from cache.\n",
            "Getting timestamps from audio file: /tmp/Video Podcast 2 SpotifyAnchor 有料エピソードを始めます rQycK6cBS8or7ft0dto.webm, start: 120, duration: 206.921\n",
            "Processing VAD in chunk from 02:00.000 to 03:26.921\n",
            "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1190: UserWarning: operator() profile_node %668 : int[] = prim::profile_ivalue(%666)\n",
            " does not have profile information (Triggered internally at ../torch/csrc/jit/codegen/cuda/graph_fuser.cpp:105.)\n",
            "  return forward_call(*input, **kwargs)\n",
            "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1190: UserWarning: operator() profile_node %668 : int[] = prim::profile_ivalue(%666)\n",
            " does not have profile information (Triggered internally at ../torch/csrc/jit/codegen/cuda/graph_fuser.cpp:105.)\n",
            "  return forward_call(*input, **kwargs)\n",
            "VAD processing took 6.367130385999985 seconds\n",
            "VAD processing took 7.317488226999984 seconds\n",
            "Transcribing non-speech:\n",
            "[{'end': 28.112000000000002, 'expand_amount': 0.0, 'start': 0.0},\n",
            " {'end': 54.4, 'expand_amount': 0.0, 'start': 28.112000000000002},\n",
            " {'end': 79.104, 'expand_amount': 0.0, 'start': 54.4},\n",
            " {'end': 108.72, 'expand_amount': 0.0, 'start': 79.104},\n",
            " {'end': 132.89600000000002, 'expand_amount': 0.0, 'start': 108.72},\n",
            " {'end': 155.40800000000002, 'expand_amount': 0.0, 'start': 132.89600000000002},\n",
            " {'end': 183.888, 'expand_amount': 0.0, 'start': 155.40800000000002},\n",
            " {'end': 206.921, 'expand_amount': 0.4830000000000041, 'start': 183.888}]\n",
            "Parallel VAD processing took 15.318324646000008 seconds\n",
            "Started auto cleanup of pool in 1800.0 seconds\n",
            "Device 0 (index 0) has 8 segments\n",
            "Using device 0\n",
            "Using override timestamps of size 8\n",
            "Processing timestamps:\n",
            "[{'end': 28.112000000000002, 'expand_amount': 0.0, 'start': 0.0},\n",
            " {'end': 54.4, 'expand_amount': 0.0, 'start': 28.112000000000002},\n",
            " {'end': 79.104, 'expand_amount': 0.0, 'start': 54.4},\n",
            " {'end': 108.72, 'expand_amount': 0.0, 'start': 79.104},\n",
            " {'end': 132.89600000000002, 'expand_amount': 0.0, 'start': 108.72},\n",
            " {'end': 155.40800000000002, 'expand_amount': 0.0, 'start': 132.89600000000002},\n",
            " {'end': 183.888, 'expand_amount': 0.0, 'start': 155.40800000000002},\n",
            " {'end': 206.921, 'expand_amount': 0.4830000000000041, 'start': 183.888}]\n",
            "Running whisper from  00:00.000  to  00:28.112 , duration:  28.112000000000002 expanded:  0.0 prompt:  None language:  None\n",
            "Loading whisper model large-v2\n",
            "100%|██████████████████████████████████████| 2.87G/2.87G [00:25<00:00, 123MiB/s]\n",
            "tcmalloc: large alloc 3087007744 bytes == 0xd086000 @  0x7f4cf13281e7 0x4d30a0 0x5dede2 0x61033f 0x5aab9b 0x47c416 0x6170f1 0x4f7916 0x4997a2 0x5d8868 0x4990ca 0x55cd91 0x5d8941 0x49abe4 0x4fd2db 0x4990ca 0x5d8868 0x4997a2 0x5d8868 0x4997a2 0x5d8868 0x4997a2 0x4fd2db 0x4997c7 0x55d078 0x5d8941 0x4fe318 0x5d8506 0x60e959 0x5d1e94 0x5d8cdf\n",
            "Running whisper from  00:28.112  to  00:54.400 , duration:  26.287999999999997 expanded:  0.0 prompt:  つまり有料のエピソードを作っていきます language:  japanese\n",
            "Running whisper from  00:54.400  to  01:19.104 , duration:  24.704 expanded:  0.0 prompt:  もちろん有料じゃないエピソードもこれからも作り続けます language:  japanese\n",
            "Running whisper from  01:19.104  to  01:48.720 , duration:  29.616 expanded:  0.0 prompt:  実はこのおまけのポッドキャストエクストラはすでにペートレオンで始まっています ペートレオンメンバー5ドルの方はもっとたく得点があって エクストラのトランスクリプションも読めます language:  japanese\n",
            "Running whisper from  01:48.720  to  02:12.896 , duration:  24.176000000000016 expanded:  0.0 prompt:  これから始まる spotify のサブスクサービスを買ってみてください language:  japanese\n",
            "Running whisper from  02:12.896  to  02:35.408 , duration:  22.512 expanded:  0.0 prompt:  私のコンテンツをサポートしたい。好きだ。のりこさんの声をもっと聞きたい。 language:  japanese\n",
            "Running whisper from  02:35.408  to  03:03.888 , duration:  28.47999999999999 expanded:  0.0 prompt:  はい、ということで皆さん、私はこれからも日々挑戦し続けます。そしてエクストラ、何が違うの?って言うかもしれない。 エクストラでは language:  japanese\n",
            "Running whisper from  03:03.888  to  03:26.921 , duration:  23.032999999999987 expanded:  0.4830000000000041 prompt:  はい、ということで皆さんよろしくお願いします。 Spotify限定有料サブスク始めますというお知らせでした。 さらに最後 language:  japanese\n",
            "Started auto cleanup of pool in 1800.0 seconds\n",
            "Parallel transcription took 144.23454933800002 seconds\n",
            "Max line width 40\n",
            "Deleting source file /tmp/Video Podcast 2 SpotifyAnchor 有料エピソードを始めます rQycK6cBS8or7ft0dto.webm\n",
            "Process SpawnPoolWorker-1:\n",
            "Process SpawnPoolWorker-3:\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Process SpawnPoolWorker-2:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/gradio/blocks.py\", line 1582, in block_thread\n",
            "    time.sleep(0.1)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"app.py\", line 397, in <module>\n",
            "    create_ui(**args)\n",
            "  File \"app.py\", line 377, in create_ui\n",
            "    demo.launch(share=share, server_name=server_name, server_port=server_port)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/gradio/blocks.py\", line 1504, in launch\n",
            "    self.block_thread()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/gradio/blocks.py\", line 1585, in block_thread\n",
            "    self.server.close()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/gradio/networking.py\", line 44, in close\n",
            "    self.thread.join()\n",
            "  File \"/usr/lib/python3.8/threading.py\", line 1011, in join\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
            "    task = get()\n",
            "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
            "    with self._rlock:\n",
            "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
            "    return self._semlock.__enter__()\n",
            "KeyboardInterrupt\n",
            "    self._wait_for_tstate_lock()\n",
            "  File \"/usr/lib/python3.8/threading.py\", line 1027, in _wait_for_tstate_lock\n",
            "    elif lock.acquire(block, timeout):\n",
            "KeyboardInterrupt\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
            "    task = get()\n",
            "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
            "    task = get()\n",
            "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 356, in get\n",
            "    res = self._reader.recv_bytes()\n",
            "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 356, in get\n",
            "    res = self._reader.recv_bytes()\n",
            "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 216, in recv_bytes\n",
            "    buf = self._recv_bytes(maxlength)\n",
            "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 216, in recv_bytes\n",
            "    buf = self._recv_bytes(maxlength)\n",
            "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 414, in _recv_bytes\n",
            "    buf = self._recv(4)\n",
            "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 414, in _recv_bytes\n",
            "    buf = self._recv(4)\n",
            "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 379, in _recv\n",
            "    chunk = read(handle, remaining)\n",
            "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 379, in _recv\n",
            "    chunk = read(handle, remaining)\n",
            "KeyboardInterrupt\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Information"
      ],
      "metadata": {
        "id": "R2mqmp4fQ3k9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optional: Get GPU Information (run this before starting the Web UI)"
      ],
      "metadata": {
        "id": "BNZoCQ7v-u2y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi -L"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRgRXEAN-yGH",
        "outputId": "5029c4a5-f84d-41bc-a2be-26946ef8afc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-c5511d0c-8750-08b5-7c7b-d7d49b9c448f)\n"
          ]
        }
      ]
    }
  ]
}